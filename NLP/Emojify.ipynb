{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given a sentence find emoji best describing the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a tiny dataset (X, Y) where:\n",
    "- X contains 127 sentences (strings)\n",
    "- Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence\n",
    "\n",
    "<img src=\"data/emoji.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> **Figure 1**: EMOJISET - a classification problem with 5 classes. A few examples of sentences are given here. </center></caption>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/w2vec.6B.50d.txt'\n",
    "tmodel = KeyedVectors.load_word2vec_format(file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vector_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence to avg for converting sentence to avg vector which will be fed to softmax classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_model):\n",
    "    \"\"\" Given a sentence break it down into words find its embedding vector and avg them out\n",
    "    return the avg\n",
    "    \"\"\"\n",
    "    \n",
    "    avg = np.zeros(word_to_vec_model['man'].shape) # avg size same as word_to_vec_model dim\n",
    "    \n",
    "    words = str(sentence).lower().split()\n",
    "    \n",
    "    for w in words:\n",
    "        avg += word_to_vec_model[w]\n",
    "    \n",
    "    \n",
    "    avg = avg/len(words)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.008005    0.56370833 -0.50427333  0.258865    0.55131104  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708966  0.18525867\n",
      "  0.64957852  0.38371118  0.21102167  0.11301667  0.02613967  0.26037766\n",
      "  0.05820667 -0.01578167 -0.12078834 -0.02471267  0.41284552  0.5152061\n",
      "  0.38756166 -0.89866098 -0.535145    0.33501166  0.68806935 -0.2156265\n",
      "  1.79715503  0.10476932 -0.36775333  0.750785    0.10282583  0.34892499\n",
      " -0.27262834  0.66767999 -0.10706167 -0.28363501  0.59580119  0.28747334\n",
      " -0.33666349  0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", tmodel)\n",
    "print(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_y_train = pd.get_dummies(y_train).as_matrix()\n",
    "onehot_y_test = pd.get_dummies(y_test).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input x to array of embedding vectors\n",
    "def convert_to_e (x):\n",
    "    x_c = np.zeros((x.size, 50))\n",
    "\n",
    "    for i in range(x.size):\n",
    "\n",
    "        x_c[i] = sentence_to_avg(x['sentence'][i], tmodel)\n",
    "\n",
    "    return x_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m = convert_to_e(X_train)\n",
    "X_test_m = convert_to_e(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 5 #classes\n",
    "learning_rate = 0.01\n",
    "num_hidden1 = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 50))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = fully_connected(X,num_hidden1,activation_fn=tf.nn.relu)\n",
    "output = fully_connected(hidden1, num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(training_steps):\n",
    "        \n",
    "        sess.run(train, feed_dict={X:X_train_m, y:onehot_y_train})\n",
    "        \n",
    "    \n",
    "    logits = output.eval(feed_dict={X:X_test_m})\n",
    "    pred = tf.argmax(logits, axis=1)\n",
    "    results = pred.eval()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 2, 2, 2, 2, 3, 2, 4, 2, 1, 2, 3, 3, 1, 3, 3, 2, 3, 4, 3, 2, 4,\n",
       "       3, 3, 3, 1, 0, 1, 2, 2, 1, 2, 2, 2, 1, 2, 4, 4, 2, 1, 3, 0, 1, 2, 1,\n",
       "       2, 2, 3, 3, 3, 3, 3, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.29      1.00      0.44         2\n",
      "          1       1.00      0.89      0.94         9\n",
      "          2       1.00      0.86      0.92        21\n",
      "          3       0.88      0.82      0.85        17\n",
      "          4       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       0.94      0.87      0.89        55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(results, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve emojify problem using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert words in input sentences to indices\n",
    "## pad the vectors to max_sentence_length\n",
    "## create a embedding matrix of shape (vocab_size, dim)\n",
    "\n",
    "vocab_size -> number of unique words in input sentences,\n",
    "dim -> glove word embedding dim (length of word vector)\n",
    "\n",
    "## use these in embedding layer for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer on total data, this will be used to represent words to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "X = train.drop('class', axis=1).append(test.drop('class', axis=1))\n",
    "token.fit_on_texts(X['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word_to_indices_pad(X, max_length):\n",
    "    \"\"\" converts a word into a vector of integers\n",
    "    \n",
    "    X -> an array of sentences\n",
    "    max_length -> max_length of sentence for padding purposes\n",
    "    \n",
    "    returns a tuple of tokenzier and padded vector of integers\n",
    "    \"\"\"\n",
    "   \n",
    "    X_indices = token.texts_to_sequences(X)\n",
    "    \n",
    "    # return tokenizer and padded vector of indices\n",
    "    return pad_sequences(X_indices, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    \"\"\" array of sentences in X, return max length of sentence\"\"\"\n",
    "    \n",
    "    max_len = 0\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        len1 = len(X[i].split())\n",
    "        \n",
    "        if len1 > max_len:\n",
    "            max_len = len1\n",
    "            \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = get_max_len(X_train['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = convert_word_to_indices_pad(X_train['sentence'], max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(t, model):\n",
    "    \"\"\" Create embedding matrix to be passed to Keras Embedding layer.\n",
    "    t -> tokenizer\n",
    "    model -> glove model\n",
    "    \n",
    "    returns a matrix of shape vocab_size, glove_vector_length\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    \n",
    "    \n",
    "    e_matrix = np.zeros((vocab_size, glove_vector_length))\n",
    "    \n",
    "    for word in t.word_index:\n",
    "        e_matrix[t.word_index[word]] = model[word]\n",
    "    \n",
    "    return e_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_matrix = create_embedding_matrix(token, tmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keras layers now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(token.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(vocab_size, glove_vector_length, trainable=False, weights=[e_matrix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_outputs))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 1.5858 - acc: 0.3182\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.5226 - acc: 0.3106\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4752 - acc: 0.3030\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4053 - acc: 0.4470\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.3082 - acc: 0.5530\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.2234 - acc: 0.5000\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.0323 - acc: 0.6591\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9250 - acc: 0.6515\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 987us/step - loss: 0.7734 - acc: 0.6970\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8266 - acc: 0.6894\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6693 - acc: 0.7500\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6394 - acc: 0.7803\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5831 - acc: 0.8030\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4959 - acc: 0.8561\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4392 - acc: 0.8561\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3815 - acc: 0.8636\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3923 - acc: 0.8636\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3814 - acc: 0.8561\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4517 - acc: 0.8333\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5766 - acc: 0.8030\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3538 - acc: 0.8636\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3530 - acc: 0.8864\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3432 - acc: 0.8712\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2854 - acc: 0.9167\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3248 - acc: 0.9091\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3684 - acc: 0.8561\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2775 - acc: 0.8939\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2061 - acc: 0.9470\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2036 - acc: 0.9242\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3345 - acc: 0.8939\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3684 - acc: 0.8788\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3859 - acc: 0.8712\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2220 - acc: 0.9167\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2131 - acc: 0.9167\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2059 - acc: 0.9470\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1659 - acc: 0.9394\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1295 - acc: 0.9621\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1500 - acc: 0.9470\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1219 - acc: 0.9621\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1122 - acc: 0.9621\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1164 - acc: 0.9621\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1282 - acc: 0.9545\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0945 - acc: 0.9621\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0860 - acc: 0.9773\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0647 - acc: 0.9848\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1356 - acc: 0.9621\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1896 - acc: 0.9242\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1707 - acc: 0.9470\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0487 - acc: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d8ec61f898>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, onehot_y_train, epochs=50, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = convert_word_to_indices_pad(X_test['sentence'], get_max_len(X_test['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_indices, onehot_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.854545442625\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see sentences where the model did not do well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sentence: she got me a nice present, actual class: 2, predicted class: 0\n",
      "For sentence: work is hard, actual class: 3, predicted class: 2\n",
      "For sentence: This girl is messing with me, actual class: 3, predicted class: 0\n",
      "For sentence: you brighten my day, actual class: 2, predicted class: 0\n",
      "For sentence: she is a bully, actual class: 3, predicted class: 0\n",
      "For sentence: My life is so boring, actual class: 3, predicted class: 0\n",
      "For sentence: go away, actual class: 3, predicted class: 1\n",
      "For sentence: yesterday we lost again, actual class: 3, predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_test_indices)):\n",
    "    predictedclass = np.argmax(pred[i])\n",
    "    \n",
    "    if (predictedclass != y_test[i]):\n",
    "        print('For sentence: ' + X_test['sentence'][i] + \", actual class: \" + str(y_test[i])\n",
    "              + \", predicted class: \" + str(predictedclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "x_dummy = np.array(['i rock'])\n",
    "x_dummy_indices = convert_word_to_indices_pad(x_dummy, get_max_len(x_dummy))\n",
    "\n",
    "print(np.argmax(model.predict(x_dummy_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
