{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Given a sentence find emoji best describing the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/w2vec.6B.50d.txt'\n",
    "model = KeyedVectors.load_word2vec_format(file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vector_length = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence to avg for converting sentence to avg vector which will be fed to softmax classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_model):\n",
    "    \"\"\" Given a sentence break it down into words find its embedding vector and avg them out\n",
    "    return the avg\n",
    "    \"\"\"\n",
    "    \n",
    "    avg = np.zeros(word_to_vec_model['man'].shape) # avg size same as word_to_vec_model dim\n",
    "    \n",
    "    words = str(sentence).lower().split()\n",
    "    \n",
    "    for w in words:\n",
    "        avg += word_to_vec_model[w]\n",
    "    \n",
    "    \n",
    "    avg = avg/len(words)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.008005    0.56370833 -0.50427333  0.258865    0.55131104  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708966  0.18525867\n",
      "  0.64957852  0.38371118  0.21102167  0.11301667  0.02613967  0.26037766\n",
      "  0.05820667 -0.01578167 -0.12078834 -0.02471267  0.41284552  0.5152061\n",
      "  0.38756166 -0.89866098 -0.535145    0.33501166  0.68806935 -0.2156265\n",
      "  1.79715503  0.10476932 -0.36775333  0.750785    0.10282583  0.34892499\n",
      " -0.27262834  0.66767999 -0.10706167 -0.28363501  0.59580119  0.28747334\n",
      " -0.33666349  0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", model)\n",
    "print(avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_y_train = pd.get_dummies(y_train).as_matrix()\n",
    "one_hot_y_test = pd.get_dummies(y_test).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input x to array of embedding vectors\n",
    "def convert_to_e (x):\n",
    "    x_c = np.zeros((x.size, 50))\n",
    "\n",
    "    for i in range(x.size):\n",
    "\n",
    "        x_c[i] = sentence_to_avg(x['sentence'][i], model)\n",
    "\n",
    "    return x_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m = convert_to_e(X_train)\n",
    "X_test_m = convert_to_e(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 5 #classes\n",
    "learning_rate = 0.01\n",
    "num_hidden1 = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32, shape=(None, 50))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = fully_connected(X,num_hidden1,activation_fn=tf.nn.relu)\n",
    "output = fully_connected(hidden1, num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(training_steps):\n",
    "        \n",
    "        sess.run(train, feed_dict={X:X_train_m, y:onehot_y_train})\n",
    "        \n",
    "    \n",
    "    logits = output.eval(feed_dict={X:X_test_m})\n",
    "    pred = tf.argmax(logits, axis=1)\n",
    "    results = pred.eval()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 0, 0, 2, 2, 3, 2, 4, 2, 1, 2, 3, 3, 1, 3, 3, 2, 3, 4, 3, 0, 4,\n",
       "       3, 3, 3, 1, 0, 1, 4, 0, 1, 0, 2, 0, 1, 2, 4, 4, 2, 1, 0, 0, 1, 2, 0,\n",
       "       2, 2, 3, 3, 3, 3, 3, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.50      0.59        10\n",
      "          1       1.00      1.00      1.00         8\n",
      "          2       0.72      0.87      0.79        15\n",
      "          3       0.88      0.88      0.88        16\n",
      "          4       0.86      0.86      0.86         7\n",
      "\n",
      "avg / total       0.82      0.82      0.82        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(results, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve emojify problem using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert words in input sentences to indices\n",
    "## pad the vectors to max_sentence_length\n",
    "## create a embedding matrix of shape (vocab_size, dim)\n",
    "\n",
    "vocab_size -> number of unique words in input sentences,\n",
    "dim -> glove word embedding dim (length of word vector)\n",
    "\n",
    "## use these in embedding layer for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word_to_indices_pad(X, max_length):\n",
    "    \"\"\" convertes a word into a vector of integers\n",
    "    \n",
    "    X -> a vector of words\n",
    "    max_length -> max_length of sentence for padding purposes\n",
    "    \n",
    "    returns a tuple of tokenzier and padded vector of integers\n",
    "    \"\"\"\n",
    "    t = Tokenizer()\n",
    "    \n",
    "    t.fit_on_texts(X)\n",
    "    X_indices = t.texts_to_sequences(X)\n",
    "    \n",
    "    # return tokenizer and padded vector of indices\n",
    "    return t, pad_sequences(X_indices, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(X):\n",
    "    \"\"\" array of sentences in X, return max length of sentence\"\"\"\n",
    "    \n",
    "    max_len = 0\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        len1 = len(X[i].split())\n",
    "        \n",
    "        if len1 > max_len:\n",
    "            max_len = len1\n",
    "            \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = get_max_len(X_train['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, X_train_indices = convert_word_to_indices_pad(X_train['sentence'], max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(t, model):\n",
    "    \"\"\" Create embedding matrix to be passed to Keras Embedding layer.\n",
    "    t -> tokenizer\n",
    "    model -> glove model\n",
    "    \n",
    "    returns a matrix of shape vocab_size, glove_vector_length\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_size = len(t.word_index) + 1\n",
    "    \n",
    "    \n",
    "    e_matrix = np.zeros((vocab_size, glove_vector_length))\n",
    "    \n",
    "    for word in t.word_index:\n",
    "        e_matrix[t.word_index[word]] = model[word]\n",
    "    \n",
    "    return e_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_matrix = create_embedding_matrix(t, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keras layers now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(vocab_size, glove_vector_length, trainable=False, weights=[e_matrix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_outputs))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 1.5950 - acc: 0.2045\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.5132 - acc: 0.3333\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4915 - acc: 0.3333\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4381 - acc: 0.4091\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.3459 - acc: 0.4242\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.2726 - acc: 0.5152\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.1510 - acc: 0.5985\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.0098 - acc: 0.6364\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8567 - acc: 0.6970\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.7357 - acc: 0.7424\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6165 - acc: 0.7879\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5442 - acc: 0.8333\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5542 - acc: 0.8182\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4691 - acc: 0.8333\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4632 - acc: 0.8561\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4399 - acc: 0.8636\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3463 - acc: 0.8864\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2976 - acc: 0.9091\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4165 - acc: 0.8561\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3546 - acc: 0.8788\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3317 - acc: 0.8864\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3465 - acc: 0.8788\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3332 - acc: 0.8864\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2304 - acc: 0.9167\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2782 - acc: 0.9091\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3085 - acc: 0.9015\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2536 - acc: 0.9242\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2433 - acc: 0.9394\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2432 - acc: 0.9318\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1826 - acc: 0.9318\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1679 - acc: 0.9545\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1094 - acc: 0.9773\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1093 - acc: 0.9773\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0940 - acc: 0.9773\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0840 - acc: 0.9848\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0969 - acc: 0.9621\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 995us/step - loss: 0.0663 - acc: 0.9848\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0505 - acc: 0.9848\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0432 - acc: 0.9924\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0308 - acc: 0.9924\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0375 - acc: 0.9848\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0305 - acc: 0.9848\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0180 - acc: 0.9924\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0239 - acc: 0.9924\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0364 - acc: 0.9924\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0065 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0d3b8c748>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, onehot_y_train, epochs=50, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, X_train_indices = convert_word_to_indices_pad(X_test['sentence'], get_max_len(X_test['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\n",
      "he did not answer\n",
      "he got a very nice raise\n",
      "she got me a nice present\n",
      "ha ha ha it was so funny\n",
      "he is a good friend\n",
      "I am upset\n",
      "We had such a lovely dinner tonight\n",
      "where is the food\n",
      "Stop making this joke ha ha ha\n",
      "where is the ball\n",
      "work is hard\n",
      "This girl is messing with me\n",
      "are you serious\n",
      "Let us go play baseball\n",
      "This stupid grader is not working \n",
      "work is horrible\n",
      "Congratulation for having a baby\n",
      "stop pissing me off\n",
      "any suggestions for dinner\n",
      "I love taking breaks\n",
      "you brighten my day\n",
      "I boiled rice\n",
      "she is a bully\n",
      "Why are you feeling bad\n",
      "I am upset\n",
      "give me the ball\n",
      "My grandmother is the love of my life\n",
      "enjoy your game\n",
      "valentine day is near\n",
      "I miss you so much\n",
      "throw the ball\n",
      "My life is so boring\n",
      "she said yes\n",
      "will you be my valentine\n",
      "he can pitch really well\n",
      "dance with me\n",
      "I am hungry\n",
      "See you at the restaurant\n",
      "I like to laugh\n",
      "I will run\n",
      "I like your jacket \n",
      "i miss her\n",
      "what is your favorite baseball game\n",
      "Good job\n",
      "I love you to the stars and back\n",
      "What you did was awesome\n",
      "ha ha ha lol\n",
      "I do not want to joke\n",
      "go away\n",
      "yesterday we lost again\n",
      "family is all I have\n",
      "you are failing this exercise\n",
      "Good joke\n",
      "You deserve this nice prize\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_len(X_test['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
